# ğŸ“Œ Plan de ModificaciÃ³n y Desarrollo (PMD)

## ğŸ—ï¸ **Objetivo**

Reestructurar la gestiÃ³n de prompts en el chat de la aplicaciÃ³n para que cada actividad tenga un flujo por pasos, asegurando escalabilidad y organizaciÃ³n sin afectar demasiado la estructura actual de la base de datos.

## ğŸ“Œ **Alcance de la ModificaciÃ³n**

- Mantener la estructura actual de la base de datos lo mÃ¡s intacta posible.
- Crear un sistema escalable de prompts organizados por actividad.
- Garantizar que cada actividad pueda validar informaciÃ³n previa antes de avanzar.
- Permitir en el futuro la integraciÃ³n con documentos en PDF o XLSX sin necesidad de cambios estructurales adicionales.
- Agregar funcionalidad para que los usuarios puedan guardar "Insights Valiosos" dentro del chat para futuras referencias.
- **Implementar un sistema de memoria conversacional optimizado** para mejorar la continuidad de la conversaciÃ³n y reducir costos.
- **Permitir que una actividad utilice informaciÃ³n de actividades anteriores, configurando esto desde el Content Manager.**
- **Optimizar la gestiÃ³n de **``** agregando **``** para una configuraciÃ³n mÃ¡s intuitiva y eliminando la columna **``**.**

## ğŸ“‚ **Estructura de Base de Datos Actual y Modificaciones MÃ­nimas**

Se aprovecharÃ¡ la estructura existente, especialmente las siguientes tablas:

- `stage_content`: Actualmente almacena contenido de etapas. Se usarÃ¡ para gestionar los prompts por actividad en lugar de por pasos.
- `activity_responses`: Se utilizarÃ¡ para almacenar las respuestas ingresadas por el usuario en cada actividad, permitiendo su recuperaciÃ³n y ediciÃ³n en caso de que el usuario regrese a una actividad anterior.
- `chat_summaries`: Se utilizarÃ¡ para almacenar resÃºmenes de conversaciones largas y optimizar la memoria de largo plazo.
- **Nueva columna en **``**:** `stage_name`, que permitirÃ¡ definir nombres mÃ¡s descriptivos para cada actividad.
- **Nueva columna en **``**:** `dependencies JSONB`, para definir quÃ© actividades previas deben usarse como contexto, almacenando directamente los valores de `stage_name` en lugar de `stage_id`. Esto permitirÃ¡ que las dependencias sean configuradas de manera mÃ¡s intuitiva en el Content Manager.
- **Eliminar la columna **``** en **``, ya que se utilizarÃ¡ un solo prompt por actividad en lugar de un sistema de pasos.
- **Nueva tabla:** `user_insights`, para almacenar ideas valiosas que el usuario quiera guardar.

### **ğŸ“Œ OptimizaciÃ³n del Chat y Memoria Conversacional**

Para mejorar la experiencia del usuario, el chat implementarÃ¡ un sistema de memoria estructurado en tres niveles:

### **1ï¸âƒ£ Memoria de Corto Plazo (Ãšltimas 10 interacciones en el frontend)**

- Se almacenan en cachÃ© las **Ãºltimas 10 interacciones** del usuario y la IA en el frontend.
- Se evita hacer mÃºltiples consultas a la base de datos para mantener fluidez.
- Cuando se supera el lÃ­mite de 10 interacciones, se descartan los mensajes mÃ¡s antiguos.

```typescript
let shortTermMemory: { role: string; content: string }[] = [];

const updateShortTermMemory = (newMessage: { role: string; content: string }) => {
  if (shortTermMemory.length >= 10) {
    shortTermMemory.shift(); // Elimina el mensaje mÃ¡s antiguo
  }
  shortTermMemory.push(newMessage);
};
```

### **2ï¸âƒ£ Memoria de Largo Plazo (ResÃºmenes en **``**)**

- Cada **10 interacciones**, se genera un resumen en `chat_summaries`.
- Los resÃºmenes permiten reducir el uso de tokens en OpenAI y evitar perder informaciÃ³n importante.
- Se eliminan interacciones antiguas de `activity_interactions` cuando se crea un resumen.

```typescript
const cleanUpInteractions = async (userId: string, activityId: string) => {
  const { data: interactions, error } = await supabase
    .from('activity_interactions')
    .select('*')
    .eq('user_id', userId)
    .eq('activity_id', activityId)
    .order('timestamp', { ascending: true });

  if (!error && interactions.length >= 10) {
    // Generar resumen con OpenAI
    const summaryPrompt = `
    Resume las siguientes interacciones manteniendo los puntos clave:
    ${interactions.map(m => `${m.role}: ${m.content}`).join("\n")}
    `;

    const summary = await callOpenAI({ messages: [{ role: "system", content: summaryPrompt }] });

    // Guardar el resumen en `chat_summaries`
    await supabase.from('chat_summaries').insert([{ 
      user_id: userId, 
      activity_id: activityId, 
      summary: summary, 
      created_at: new Date().toISOString()
    }]);

    // Eliminar interacciones antiguas para liberar espacio
    for (const interaction of interactions) {
      await supabase.from('activity_interactions').delete().eq('id', interaction.id);
    }
  }
};
```

### **3ï¸âƒ£ RecuperaciÃ³n de Contexto para OpenAI**

Cada vez que OpenAI recibe un mensaje, se le envÃ­a: âœ… **Las Ãºltimas 10 interacciones en cachÃ©.** âœ… **El Ãºltimo resumen de **``**, si existe.** âœ… **Las instrucciones del paso actual.** âœ… **El perfil de la empresa, si estÃ¡ disponible.** âœ… **Las respuestas previas de actividades relacionadas, si existen.**

```typescript
const generateContextForOpenAI = async (userId: string, activityId: string, userInput: string) => {
  let chatHistory = [...shortTermMemory];

  // Obtener respuestas previas si hay dependencias
  const dependencies = await fetchDependencies(activityId);
  if (dependencies.length > 0) {
    const previousResponses = await fetchPreviousResponses(userId, dependencies);
    if (previousResponses) {
      chatHistory.unshift({ role: "system", content: `InformaciÃ³n relevante de actividades previas: ${JSON.stringify(previousResponses)}` });
    }
  }

  // Obtener el perfil de la empresa
  const companyProfile = await fetchCompanyProfile(userId);
  if (companyProfile) {
    chatHistory.unshift({ role: "system", content: `Contexto de la empresa: ${JSON.stringify(companyProfile)}` });
  }

  // Obtener el Ãºltimo resumen de memoria de largo plazo
  const { data: longTermMemory, error } = await supabase
    .from('chat_summaries')
    .select('summary')
    .eq('user_id', userId)
    .eq('activity_id', activityId)
    .order('created_at', { ascending: false })
    .limit(1);

  if (!error && longTermMemory.length > 0) {
    chatHistory.unshift({ role: "system", content: longTermMemory[0].summary });
  }

  chatHistory.push({ role: "user", content: userInput });
  return chatHistory;
};
```

## **ğŸš€ ConclusiÃ³n**

âœ… **Se implementa una memoria conversacional escalonada para optimizar el rendimiento del chat.**\
âœ… **Las dependencias entre actividades se configuran con **``**, facilitando la gestiÃ³n en el Content Manager.**\
âœ… **El sistema consulta automÃ¡ticamente respuestas previas y las envÃ­a a OpenAI sin duplicar informaciÃ³n.**\
âœ… **El usuario tiene una experiencia mÃ¡s fluida sin repetir informaciÃ³n que ya ha dado.**

ğŸš€ **Con esta implementaciÃ³n, la configuraciÃ³n y uso del chat serÃ¡n mÃ¡s eficientes y escalables.**

